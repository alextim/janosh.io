---
title: Training BNNs with HMC
slug: /hmc-bnn
date: 2019-08-30
cover:
  img: hmc-bnn.svg
tags:
  - Python
  - Machine Learning
showToc: true
---

In this post, I want to give a brief guide on how to use the [Hamiltonian Monte Carlo (HMC) transition kernel](https://www.tensorflow.org/probability/api_docs/python/tfp/mcmc/HamiltonianMonteCarlo) provided by [TensorFlow Probability](https://www.tensorflow.org/probability) to train Bayesian neural networks (BNN) in a rigorous manner by sampling from their true posterior distribution. If you haven't heard of HMC before, check out this [short introduction](/blog/hmc-intro). Or, if you just want the 30-second elevator pitch: HMC is a Markov chain Monte Carlo (MCMC) algorithm that avoids the random walk behavior of simpler MCMC methods such as Metropolis-Hastings or Gibbs sampling by using Hamilton's equations of classical mechanics to take a series of first-order-gradient-informed steps through an auxiliary phase space which can be projected down onto the probability density you care about. This allows it to converge for even very high-dimensional target distributions while at the same time generating a Markov chain of less correlated samples.

> This guide is written for [TensorFlow v2.0](https://pypi.org/project/tensorflow) and uses [TensorFlow Probability v0.9](https://pypi.org/project/tensorflow-probability).

```py
import logging
from datetime import datetime
from functools import partial

import tensorflow as tf
import tensorflow_probability as tfp

from src.nn.hmc.utils import ess, plot_1d_chain_histogram, plot_neg_log_likelihood
from src.utils.decorators import timed

tfd = tfp.distributions


def trace_fn(state, results, summary_freq=10):
    step = results.step
    with tf.summary.record_if(tf.equal(step % summary_freq, 0)):
        tf.summary.scalar("state", state, step=step)
    return results


@tf.function
def graph_hmc(*args, **kwargs):
    """compile a static graph for creating a Markov chain with HMC
    this is the main computation and significantly improves performance
    (empirically by a factor of ~5x)
    """
    return tfp.mcmc.sample_chain(*args, **kwargs)


@timed
def run_hmc(
    target_log_prob_fn,
    step_size=0.1,
    num_leapfrog_steps=3,
    num_adaptation_steps=100,
    num_results=1000,
    num_steps_between_results=0,
    current_state=0.0,
    logdir="data/output/simple_hmc/",
    resume=None,
):
    """Populates a Markov chain by performing `num_results` gradient-informed steps with a
    Hamiltonian Monte Carlo transition kernel to produce a Metropolis proposal and either
    appending that or the previous state to the chain.

    Arguments:
        target_log_prob_fn {callable}: Determines the HMC transition kernel
        and thereby the stationary distribution that the Markov chain approximates.

    Keyword Arguments:
        step_size {float}: [description] (default: {0.1})
        num_leapfrog_steps {int}: Number of steps to run the leapfrog integrator for.
            Total progress per HMC step is roughly proportional to step_size * num_leapfrog_steps.
            Not to be confused with steps in the Markov chain itself. (default: {3})
        num_adaptation_steps {int}: [description] (default: {100})
        num_steps_between_results {int}: thins the chain by performing multiple
            steps for every added sample to reduce auto-correlation (default: {0})
        num_results {int}: [description] (default: {1000})
        current_state {float}: [description] (default: {0.0})

    Returns:
        chain: The Markov chain.
        (state, kernel_results): 2-tuple of the chain's state and the
            results of the kernel such as log probabilities of sampled points
            and acceptance rate.
    """
    # Set up logging.
    stamp = datetime.now().strftime("%m-%d@%H:%M:%S")
    logdir = logdir + stamp
    summary_writer = tf.summary.create_file_writer(logdir)

    hmc_kernel = tfp.mcmc.HamiltonianMonteCarlo(
        target_log_prob_fn, step_size=step_size, num_leapfrog_steps=num_leapfrog_steps
    )
    adaptive_kernel = tfp.mcmc.SimpleStepSizeAdaptation(
        hmc_kernel, num_adaptation_steps=num_adaptation_steps
    )
    if resume is None:
        prev_kernel_results = adaptive_kernel.bootstrap_results(current_state)
        step = 0
    else:
        prev_chain, prev_trace, prev_kernel_results = resume
        step = len(prev_chain)
        current_state = tf.nest.map_structure(lambda chain: chain[-1], prev_chain)

    tf.summary.trace_on(graph=True, profiler=True)
    chain, trace, final_kernel_results = graph_hmc(
        kernel=adaptive_kernel,
        current_state=current_state,
        num_results=num_results,
        previous_kernel_results=prev_kernel_results,
        num_steps_between_results=num_steps_between_results,
        trace_fn=partial(trace_fn, summary_freq=5),
        return_final_kernel_results=True,
    )
    with summary_writer.as_default():
        tf.summary.trace_export(
            name="mcmc_sample_trace", step=step, profiler_outdir=logdir
        )
    summary_writer.close()

    if resume:
        chain = tf.concat((prev_chain, chain), axis=0)
        trace = tf.nest.map_structure(
            lambda *parts: tf.concat(parts, axis=0), prev_trace, trace
        )

    return chain, trace, final_kernel_results


dist = tfd.Normal(0.0, 1.0)

results = run_hmc(dist.log_prob, num_results=500)

chain, trace, final_kernel_results = run_hmc(
    dist.log_prob, num_results=500, resume=results
)


logging.info(f"effective sample size: {ess(chain)} for a chain of length {len(chain)}")

target_log_probs = trace.inner_results.accepted_results.target_log_prob
plot_neg_log_likelihood(target_log_probs)


plot_1d_chain_histogram(chain)

accept_rate = trace.inner_results.is_accepted.numpy().mean()
print("Acceptance rate:", accept_rate)
```

## Things to look forward to

TFP has two samplers lined up that should make its HMC kernel converge to better step sizes faster and scale to even larger problems both in terms of state space dimensionality and the number of data points, respectively:

- [`DualAveragingStepSizeAdaptation`](https://github.com/tensorflow/probability/blob/23573a10f203bf740e69f52387bbe8070703eda5/tensorflow_probability/python/mcmc/dual_averaging_step_size_adaptation.py#L97): This sampler was added by Colin Carroll in [this PR](https://github.com/tensorflow/probability/pull/375) which was merged on August 1. It's not documented yet at this point but is already part of the latest [`tfp-nightly`](https://pypi.org/project/tfp-nightly).
- [`NoUTurnSampler`](https://github.com/tensorflow/probability/blob/23573a10f203bf740e69f52387bbe8070703eda5/tensorflow_probability/python/experimental/mcmc/nuts.py#L75):


## Further reading

- [A tour of probabilistic programming language APIs](https://colcarroll.github.io/ppl-api) by Colin Carroll
